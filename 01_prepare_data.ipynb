{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0a8285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c012c2",
   "metadata": {},
   "source": [
    "### 1. Настройка API TMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a93f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/popular?api_key=64cff5eb8f8dc04937d31db59bc01d80&language=ru-RU&page=1 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f5f830412d0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/urllib3/connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/urllib3/connectionpool.py:488\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    487\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/urllib3/connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/urllib3/connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1093\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/urllib3/connection.py:704\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    703\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/urllib3/connection.py:213\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    217\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f5f830412d0>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/urllib3/connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/popular?api_key=64cff5eb8f8dc04937d31db59bc01d80&language=ru-RU&page=1 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f5f830412d0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m TMDB_API_KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m64cff5eb8f8dc04937d31db59bc01d80\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.themoviedb.org/3/movie/popular?api_key=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTMDB_API_KEY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&language=ru-RU&page=1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m movies \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m movies\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/ocr/lib/python3.10/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/popular?api_key=64cff5eb8f8dc04937d31db59bc01d80&language=ru-RU&page=1 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f5f830412d0>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "TMDB_API_KEY = \"<TMDB API KEY>\"\n",
    "url = f\"https://api.themoviedb.org/3/movie/popular?api_key={TMDB_API_KEY}&language=ru-RU&page=1\"\n",
    "\n",
    "response = requests.get(url)\n",
    "movies = response.json()[\"results\"]\n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ed58a",
   "metadata": {},
   "source": [
    "### 2. Сбор метаданных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599ab25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шаг 1: Получение списка фильмов из разных категорий\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67bd979ee644fa28411711e5467ddc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Запрос разных категорий:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собрано 580 уникальных фильмов\n",
      "Шаг 2: Получение детальной информации о фильмах\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c8284d204a4ef0baec43b1e57e73f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Получение детальной информации:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сбор метаданных завершен!\n",
      "Собрана детальная информация о 500 фильмах\n",
      "Ошибки при получении данных для 0 фильмов\n",
      "Результаты сохранены в директории: movie_data\n",
      "\n",
      "Пример данных о первом фильме:\n",
      "Название: Мстители\n",
      "Год: 2012\n",
      "Жанры: фантастика, боевик, приключения\n",
      "Режиссер: Джосс Уидон\n"
     ]
    }
   ],
   "source": [
    "NUM_MOVIES = 500\n",
    "OUTPUT_DIR = \"movie_data\"\n",
    "LANGUAGE = \"ru-RU\"\n",
    "\n",
    "def get_diverse_movies(api_key, num_movies=500, language=\"ru-RU\"):\n",
    "    all_movies = []\n",
    "    movie_ids = set()\n",
    "    \n",
    "    endpoints = [\n",
    "        \"movie/popular\",\n",
    "        \"movie/top_rated\",\n",
    "        \"discover/movie?sort_by=vote_count.desc\",\n",
    "        \"discover/movie?with_genres=28\",  # Боевики\n",
    "        \"discover/movie?with_genres=35\",  # Комедии\n",
    "        \"discover/movie?with_genres=18\",  # Драмы\n",
    "        \"discover/movie?with_genres=27\",  # Ужасы\n",
    "        \"discover/movie?with_genres=10749\", # Романтика\n",
    "        \"discover/movie?with_genres=878\"   # Научная фантастика\n",
    "    ]\n",
    "    \n",
    "    years = list(range(1980, 2024, 5))\n",
    "    for year in years:\n",
    "        endpoints.append(f\"discover/movie?primary_release_year={year}&sort_by=popularity.desc\")\n",
    "    \n",
    "    target_per_endpoint = num_movies // len(endpoints) + 1\n",
    "    pages_per_endpoint = (target_per_endpoint + 19) // 20\n",
    "    \n",
    "    for endpoint in tqdm(endpoints, desc=\"Запрос разных категорий\"):\n",
    "        endpoint_movies = 0\n",
    "        \n",
    "        for page in range(1, pages_per_endpoint + 1):\n",
    "            if \"?\" in endpoint:\n",
    "                url = f\"https://api.themoviedb.org/3/{endpoint}&api_key={api_key}&language={language}&page={page}\"\n",
    "            else:\n",
    "                url = f\"https://api.themoviedb.org/3/{endpoint}?api_key={api_key}&language={language}&page={page}\"\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(url)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    page_data = response.json()\n",
    "                    \n",
    "                    for movie in page_data[\"results\"]:\n",
    "                        if movie[\"id\"] not in movie_ids and \"release_date\" in movie and movie[\"release_date\"]:\n",
    "                            all_movies.append(movie)\n",
    "                            movie_ids.add(movie[\"id\"])\n",
    "                            endpoint_movies += 1\n",
    "                    \n",
    "                    if endpoint_movies >= target_per_endpoint:\n",
    "                        break\n",
    "                        \n",
    "                    time.sleep(0.5)\n",
    "                elif response.status_code == 429:\n",
    "                    print(f\"Превышен лимит запросов. Ожидание 10 секунд...\")\n",
    "                    time.sleep(10)\n",
    "                    page -= 1\n",
    "                else:\n",
    "                    print(f\"Ошибка при загрузке {endpoint}, страница {page}: {response.status_code}\")\n",
    "                    time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print(f\"Исключение при запросе {url}: {e}\")\n",
    "                time.sleep(2)\n",
    "    \n",
    "    print(f\"Собрано {len(all_movies)} уникальных фильмов\")\n",
    "    \n",
    "    random.shuffle(all_movies)\n",
    "    return all_movies[:num_movies]\n",
    "\n",
    "def get_movie_details(movie_id, api_key, language=\"ru-RU\"):\n",
    "    time.sleep(random.uniform(0.2, 0.7))\n",
    "    \n",
    "    movie_url = f\"https://api.themoviedb.org/3/movie/{movie_id}?api_key={api_key}&language={language}&append_to_response=credits,keywords\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(movie_url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            movie_data = response.json()\n",
    "            \n",
    "            movie_details = {\n",
    "                \"id\": movie_data[\"id\"],\n",
    "                \"title\": movie_data[\"title\"],\n",
    "                \"original_title\": movie_data[\"original_title\"],\n",
    "                \"release_date\": movie_data.get(\"release_date\", \"\"),\n",
    "                \"year\": movie_data[\"release_date\"][:4] if movie_data.get(\"release_date\") else None,\n",
    "                \"genres\": [genre[\"name\"] for genre in movie_data.get(\"genres\", [])],\n",
    "                \"overview\": movie_data.get(\"overview\", \"\"),\n",
    "                \"poster_path\": movie_data.get(\"poster_path\"),\n",
    "                \"backdrop_path\": movie_data.get(\"backdrop_path\"),\n",
    "                \"popularity\": movie_data.get(\"popularity\"),\n",
    "                \"vote_average\": movie_data.get(\"vote_average\"),\n",
    "                \"runtime\": movie_data.get(\"runtime\"),\n",
    "            }\n",
    "            \n",
    "            if \"credits\" in movie_data:\n",
    "                directors = [person[\"name\"] for person in movie_data[\"credits\"].get(\"crew\", []) \n",
    "                            if person.get(\"job\") == \"Director\"]\n",
    "                movie_details[\"director\"] = directors[0] if directors else None\n",
    "                \n",
    "                cast = movie_data[\"credits\"].get(\"cast\", [])\n",
    "                movie_details[\"cast\"] = [person[\"name\"] for person in cast[:5]]\n",
    "            \n",
    "            if \"keywords\" in movie_data and \"keywords\" in movie_data[\"keywords\"]:\n",
    "                movie_details[\"keywords\"] = [kw[\"name\"] for kw in movie_data[\"keywords\"][\"keywords\"]]\n",
    "            \n",
    "            return movie_details\n",
    "        \n",
    "        elif response.status_code == 429:\n",
    "            print(f\"Превышен лимит запросов для фильма {movie_id}. Ожидание 10 секунд...\")\n",
    "            time.sleep(10)\n",
    "            return get_movie_details(movie_id, api_key, language)\n",
    "        else:\n",
    "            print(f\"Ошибка при получении информации о фильме {movie_id}: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Исключение при получении данных о фильме {movie_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Шаг 1: Получение списка фильмов из разных категорий\")\n",
    "movies_list = get_diverse_movies(TMDB_API_KEY, num_movies=NUM_MOVIES, language=LANGUAGE)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, \"movies_list.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(movies_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Шаг 2: Получение детальной информации о фильмах\")\n",
    "detailed_movies = {}\n",
    "errors = []\n",
    "\n",
    "for movie in tqdm(movies_list, desc=\"Получение детальной информации\"):\n",
    "    movie_id = movie[\"id\"]\n",
    "    movie_details = get_movie_details(movie_id, TMDB_API_KEY, LANGUAGE)\n",
    "    \n",
    "    if movie_details:\n",
    "        detailed_movies[str(movie_id)] = movie_details\n",
    "    else:\n",
    "        errors.append(movie_id)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, \"detailed_movies.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(detailed_movies, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "if errors:\n",
    "    with open(os.path.join(OUTPUT_DIR, \"errors.json\"), \"w\") as f:\n",
    "        json.dump(errors, f)\n",
    "\n",
    "print(f\"Сбор метаданных завершен!\")\n",
    "print(f\"Собрана детальная информация о {len(detailed_movies)} фильмах\")\n",
    "print(f\"Ошибки при получении данных для {len(errors)} фильмов\")\n",
    "print(f\"Результаты сохранены в директории: {OUTPUT_DIR}\")\n",
    "\n",
    "if detailed_movies:\n",
    "    first_movie_id = next(iter(detailed_movies))\n",
    "    print(\"\\nПример данных о первом фильме:\")\n",
    "    print(f\"Название: {detailed_movies[first_movie_id]['title']}\")\n",
    "    print(f\"Год: {detailed_movies[first_movie_id].get('year')}\")\n",
    "    print(f\"Жанры: {', '.join(detailed_movies[first_movie_id].get('genres', []))}\")\n",
    "    print(f\"Режиссер: {detailed_movies[first_movie_id].get('director')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d89843",
   "metadata": {},
   "source": [
    "### 3. Сбор кадров к фильмам с TMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "INPUT_FILE = \"movie_data/detailed_movies.json\"\n",
    "OUTPUT_DIR = \"movie_data/frames\"\n",
    "MAX_FRAMES_PER_MOVIE = 30\n",
    "MIN_WIDTH = 500\n",
    "MIN_BRIGHTNESS = 30 \n",
    "MIN_FILE_SIZE = 20000  # bytes\n",
    "MAX_THREADS = 5\n",
    "\n",
    "TMDB_IMAGE_BASE_URL = \"https://image.tmdb.org/t/p/original\"\n",
    "TMDB_API_URL = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "MOVIE_STILLS_DB_BASE_URL = \"https://www.moviestillsdb.com/movies\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    movies_metadata = json.load(f)\n",
    "\n",
    "print(f\"Загружены метаданные для {len(movies_metadata)} фильмов\")\n",
    "\n",
    "def get_movie_frames_from_tmdb(movie_id, api_key, max_frames=15):\n",
    "    images_url = f\"{TMDB_API_URL}/movie/{movie_id}/images?api_key={api_key}&include_image_language=en,null,ru\"\n",
    "    \n",
    "    frame_urls = []\n",
    "    try:\n",
    "        response = requests.get(images_url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            image_data = response.json()\n",
    "            \n",
    "            stills = image_data.get(\"stills\", [])\n",
    "            \n",
    "            if stills:\n",
    "                stills = sorted(stills, key=lambda x: x.get(\"width\", 0) * x.get(\"height\", 0), reverse=True)\n",
    "                \n",
    "                for still in stills[:max_frames]:\n",
    "                    frame_urls.append(f\"{TMDB_IMAGE_BASE_URL}{still['file_path']}\")\n",
    "            \n",
    "            if len(frame_urls) < max_frames:\n",
    "                backdrops = image_data.get(\"backdrops\", [])\n",
    "                backdrops = sorted(backdrops, key=lambda x: x.get(\"width\", 0) * x.get(\"height\", 0), reverse=True)\n",
    "                \n",
    "                for backdrop in backdrops[:max_frames - len(frame_urls)]:\n",
    "                    frame_urls.append(f\"{TMDB_IMAGE_BASE_URL}{backdrop['file_path']}\")\n",
    "        \n",
    "        elif response.status_code == 429:\n",
    "            print(f\"Превышен лимит запросов для кадров фильма {movie_id}. Ожидание 10 секунд...\")\n",
    "            time.sleep(10)\n",
    "            return get_movie_frames_from_tmdb(movie_id, api_key, max_frames)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при получении кадров для фильма {movie_id}: {e}\")\n",
    "    \n",
    "    return frame_urls\n",
    "\n",
    "\n",
    "\n",
    "def search_alternate_sources(movie_data, max_frames=15):\n",
    "    frame_urls = []\n",
    "    \n",
    "    title = movie_data.get(\"original_title\", \"\").replace(\" \", \"-\").lower()\n",
    "    year = movie_data.get(\"year\", \"\")\n",
    "    \n",
    "    if title and year:\n",
    "        pass\n",
    "    \n",
    "    return frame_urls\n",
    "\n",
    "def download_and_validate_frame(url, output_path, min_width=500, min_brightness=30, min_file_size=20000):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return False\n",
    "        \n",
    "        if len(response.content) < min_file_size:\n",
    "            return False\n",
    "        \n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        width, height = image.size\n",
    "        if width < min_width:\n",
    "            return False\n",
    "        \n",
    "        img_gray = image.convert('L')\n",
    "        brightness = np.mean(np.array(img_gray))\n",
    "        if brightness < min_brightness:\n",
    "            return False\n",
    "        \n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке {url}: {e}\")\n",
    "        return False\n",
    "\n",
    "def process_movie(movie_id, movie_data, output_dir, api_key, max_frames=30):\n",
    "    movie_dir = os.path.join(output_dir, str(movie_id))\n",
    "    os.makedirs(movie_dir, exist_ok=True)\n",
    "    \n",
    "    stats = {\n",
    "        \"downloaded\": 0,\n",
    "        \"filtered\": 0,\n",
    "        \"errors\": 0\n",
    "    }\n",
    "    \n",
    "    tmdb_frames = get_movie_frames_from_tmdb(movie_id, api_key, max_frames)\n",
    "    \n",
    "    alt_frames = []\n",
    "    if len(tmdb_frames) < max_frames:\n",
    "        alt_frames = search_alternate_sources(movie_data, max_frames - len(tmdb_frames))\n",
    "    \n",
    "    all_frame_urls = tmdb_frames + alt_frames\n",
    "    \n",
    "    for i, url in enumerate(all_frame_urls):\n",
    "        output_path = os.path.join(movie_dir, f\"frame_{i:03d}.jpg\")\n",
    "        \n",
    "        if os.path.exists(output_path):\n",
    "            stats[\"downloaded\"] += 1\n",
    "            continue\n",
    "        \n",
    "        time.sleep(random.uniform(0.2, 0.5))\n",
    "        \n",
    "        if download_and_validate_frame(\n",
    "            url, \n",
    "            output_path, \n",
    "            min_width=MIN_WIDTH,\n",
    "            min_brightness=MIN_BRIGHTNESS,\n",
    "            min_file_size=MIN_FILE_SIZE\n",
    "        ):\n",
    "            stats[\"downloaded\"] += 1\n",
    "        else:\n",
    "            stats[\"filtered\"] += 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def process_all_movies():\n",
    "    total_stats = {\"downloaded\": 0, \"filtered\": 0, \"errors\": 0, \"movies_with_frames\": 0}\n",
    "    movie_frame_counts = {}\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "        future_to_movie = {\n",
    "            executor.submit(\n",
    "                process_movie, \n",
    "                movie_id, \n",
    "                movie_data, \n",
    "                OUTPUT_DIR, \n",
    "                TMDB_API_KEY, \n",
    "                MAX_FRAMES_PER_MOVIE\n",
    "            ): (movie_id, movie_data) \n",
    "            for movie_id, movie_data in movies_metadata.items()\n",
    "        }\n",
    "        \n",
    "        for future in tqdm(concurrent.futures.as_completed(future_to_movie), total=len(movies_metadata), desc=\"Обработка фильмов\"):\n",
    "            movie_id, movie_data = future_to_movie[future]\n",
    "            \n",
    "            try:\n",
    "                stats = future.result()\n",
    "                \n",
    "                total_stats[\"downloaded\"] += stats[\"downloaded\"]\n",
    "                total_stats[\"filtered\"] += stats[\"filtered\"]\n",
    "                total_stats[\"errors\"] += stats[\"errors\"]\n",
    "                \n",
    "                movie_dir = os.path.join(OUTPUT_DIR, str(movie_id))\n",
    "                if os.path.exists(movie_dir):\n",
    "                    frame_count = len([f for f in os.listdir(movie_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "                    movie_frame_counts[movie_id] = frame_count\n",
    "                    \n",
    "                    if frame_count > 0:\n",
    "                        total_stats[\"movies_with_frames\"] += 1\n",
    "                        print(f\"Скачано {frame_count} кадров для фильма {movie_data.get('title')}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при обработке фильма {movie_id}: {e}\")\n",
    "                total_stats[\"errors\"] += 1\n",
    "    \n",
    "    return total_stats, movie_frame_counts\n",
    "\n",
    "print(\"Начинаем скачивание кадров из фильмов...\")\n",
    "total_stats, movie_frame_counts = process_all_movies()\n",
    "\n",
    "for movie_id in movies_metadata:\n",
    "    movies_metadata[movie_id][\"frame_count\"] = movie_frame_counts.get(movie_id, 0)\n",
    "\n",
    "updated_metadata_file = os.path.join(os.path.dirname(INPUT_FILE), \"movies_with_frames.json\")\n",
    "with open(updated_metadata_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(movies_metadata, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"\\nСтатистика скачивания:\")\n",
    "print(f\"Всего скачано кадров: {total_stats['downloaded']}\")\n",
    "print(f\"Отфильтровано низкокачественных кадров: {total_stats['filtered']}\")\n",
    "print(f\"Ошибок при скачивании: {total_stats['errors']}\")\n",
    "print(f\"Фильмов с кадрами: {total_stats['movies_with_frames']} из {len(movies_metadata)}\")\n",
    "\n",
    "print(\"\\nФильмы с наибольшим количеством кадров:\")\n",
    "top_movies = sorted(movie_frame_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "for movie_id, count in top_movies:\n",
    "    if movie_id in movies_metadata:\n",
    "        print(f\"{movies_metadata[movie_id]['title']}: {count} кадров\")\n",
    "\n",
    "def visualize_random_frames(num_movies=3, frames_per_movie=3):\n",
    "    \"\"\"Показывает случайные кадры из случайных фильмов\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    movies_with_frames = [movie_id for movie_id, count in movie_frame_counts.items() if count >= frames_per_movie]\n",
    "    \n",
    "    if not movies_with_frames or len(movies_with_frames) < num_movies:\n",
    "        print(\"Недостаточно фильмов с кадрами для визуализации\")\n",
    "        return\n",
    "    \n",
    "    sampled_movies = random.sample(movies_with_frames, num_movies)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_movies, frames_per_movie, figsize=(15, 4 * num_movies))\n",
    "    \n",
    "    for i, movie_id in enumerate(sampled_movies):\n",
    "        movie_dir = os.path.join(OUTPUT_DIR, str(movie_id))\n",
    "        frame_files = [f for f in os.listdir(movie_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        if len(frame_files) < frames_per_movie:\n",
    "            continue\n",
    "            \n",
    "        sampled_frames = random.sample(frame_files, frames_per_movie)\n",
    "        \n",
    "        for j, frame_file in enumerate(sampled_frames):\n",
    "            frame_path = os.path.join(movie_dir, frame_file)\n",
    "            img = Image.open(frame_path)\n",
    "            \n",
    "            if num_movies == 1:\n",
    "                ax = axes[j]\n",
    "            else:\n",
    "                ax = axes[i, j]\n",
    "                \n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"{movies_metadata[movie_id]['title']}\\n{frame_file}\")\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if total_stats[\"movies_with_frames\"] >= 3:\n",
    "    try:\n",
    "        visualize_random_frames(num_movies=3, frames_per_movie=3)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при визуализации кадров: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49194d30",
   "metadata": {},
   "source": [
    "### 4. Сбор кадров из дополнительных источников"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07313c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск сбора дополнительных кадров из альтернативных источников...\n",
      "Максимальное количество кадров для каждого фильма: 100\n",
      "Количество параллельных потоков: 5\n",
      "Загрузка метаданных из файла movie_data/movies_with_frames.json\n",
      "Загружены метаданные для 500 фильмов\n",
      "Обработка ограничена 10 фильмами\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07c7855dc834339b1f9833b0154d5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Дополнительные кадры:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при получении IMDB ID: HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/1297763/external_ids?api_key=64cff5eb8f8dc04937d31db59bc01d80 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4abc4a1fc0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "Ошибка при получении IMDB ID: HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/11688/external_ids?api_key=64cff5eb8f8dc04937d31db59bc01d80 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4abc4a3d00>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "Ошибка при получении IMDB ID: HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/234121/external_ids?api_key=64cff5eb8f8dc04937d31db59bc01d80 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4abc4a1720>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "Ошибка при получении IMDB ID: HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/1450436/external_ids?api_key=64cff5eb8f8dc04937d31db59bc01d80 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4abc4a3460>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "Ошибка при получении IMDB ID: HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/259872/external_ids?api_key=64cff5eb8f8dc04937d31db59bc01d80 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4abc4a25c0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "Ошибка при получении IMDB ID: HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/845781/external_ids?api_key=64cff5eb8f8dc04937d31db59bc01d80 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4abc392b90>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "Ошибка при получении IMDB ID: HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/1226406/external_ids?api_key=64cff5eb8f8dc04937d31db59bc01d80 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4abc3933d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "Ошибка при получении IMDB ID: HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/41003/external_ids?api_key=64cff5eb8f8dc04937d31db59bc01d80 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4abc3b0760>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "Ошибка при получении IMDB ID: HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/9399/external_ids?api_key=64cff5eb8f8dc04937d31db59bc01d80 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4abc4eed70>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "Ошибка при получении IMDB ID: HTTPSConnectionPool(host='api.themoviedb.org', port=443): Max retries exceeded with url: /3/movie/129/external_ids?api_key=64cff5eb8f8dc04937d31db59bc01d80 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4abc4ee0b0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "Film-Grab: Использую первый результат для Red One (2024): The Matrix Resurrections\n",
      "Film-Grab: Получено 65 кадров для The Matrix Resurrections\n",
      "Film-Grab: Использую первый результат для White Palace (1990): Dune: Part 2\n",
      "Film-Grab: Получено 65 кадров для Dune: Part 2\n",
      "Добавлено 52 кадров для фильма Миссия: Красный из источников: FilmGrab\n",
      "Добавлено 49 кадров для фильма Белый дворец из источников: FilmGrab\n",
      "\n",
      "Статистика дополнительных кадров:\n",
      "Всего скачано новых кадров: 101\n",
      "Отфильтровано низкокачественных кадров: 29\n",
      "Ошибок при скачивании: 0\n",
      "Использованы источники: FilmGrab\n",
      "\n",
      "Фильмы с наибольшим количеством кадров:\n",
      "Миссия: Красный: 81 кадров\n",
      "Белый дворец: 51 кадров\n",
      "Любовь - Боль: 30 кадров\n",
      "Унесённые призраками: 29 кадров\n",
      "Самоволка: 21 кадров\n",
      "Похождения императора: 20 кадров\n",
      "Бэтмен-ниндзя против Лиги якудза: 19 кадров\n",
      "Des jours plus belles que la nuit: 13 кадров\n",
      "Огненный опал: Торговцы телом: 2 кадров\n",
      "Puri for Rent: 2 кадров\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from tqdm.notebook import tqdm\n",
    "import concurrent.futures\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote, urljoin\n",
    "from difflib import SequenceMatcher \n",
    "\n",
    "INPUT_FILE = \"movie_data/movies_with_frames.json\"\n",
    "OUTPUT_DIR = \"movie_data/frames\"\n",
    "MAX_FRAMES_PER_MOVIE = 100\n",
    "MIN_WIDTH = 500\n",
    "MIN_BRIGHTNESS = 30\n",
    "MIN_FILE_SIZE = 20000\n",
    "MAX_THREADS = 5\n",
    "USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "TMDB_API_KEY = \"<TMDB API KEY>\" \n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def similar(a, b, threshold=0.6):\n",
    "    a = a.lower().strip()\n",
    "    b = b.lower().strip()\n",
    "    \n",
    "    for prefix in [\"the \", \"a \", \"an \"]:\n",
    "        if a.startswith(prefix):\n",
    "            a = a[len(prefix):]\n",
    "        if b.startswith(prefix):\n",
    "            b = b[len(prefix):]\n",
    "    \n",
    "    similarity = SequenceMatcher(None, a, b).ratio()\n",
    "    \n",
    "    contains = a in b or b in a\n",
    "    \n",
    "    return similarity >= threshold or contains\n",
    "\n",
    "def get_imdb_id(tmdb_id, api_key=None):\n",
    "    if not api_key:\n",
    "        return None\n",
    "    \n",
    "    url = f\"https://api.themoviedb.org/3/movie/{tmdb_id}/external_ids?api_key={api_key}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return data.get(\"imdb_id\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при получении IMDB ID: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def load_movie_metadata(file_path):\n",
    "    print(f\"Загрузка метаданных из файла {file_path}\")\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"Загружены метаданные для {len(metadata)} фильмов\")\n",
    "        return metadata\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке метаданных: {e}\")\n",
    "        return {}\n",
    "\n",
    "def get_frames_from_movie_stills_db(movie_title, year, imdb_id=None, max_frames=15):\n",
    "    frame_urls = []\n",
    "    \n",
    "    base_url = \"https://www.moviestillsdb.com\"\n",
    "    \n",
    "    urls_to_try = []\n",
    "    \n",
    "    if imdb_id and imdb_id.startswith('tt'):\n",
    "        urls_to_try.append((f\"{base_url}/movies/i{imdb_id}\", True))\n",
    "    \n",
    "    formatted_title = movie_title.lower().replace(' ', '-')\n",
    "    formatted_title = re.sub(r'[^\\w\\-]', '', formatted_title)\n",
    "    \n",
    "    urls_to_try.append((f\"{base_url}/movies/{formatted_title}-{year}\", True))\n",
    "    urls_to_try.append((f\"{base_url}/movies/{formatted_title}\", False))\n",
    "    \n",
    "    search_url = f\"{base_url}/search/?query={quote(movie_title)}\"\n",
    "    urls_to_try.append((search_url, False))\n",
    "    \n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    \n",
    "    for url, is_reliable in urls_to_try:\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=15)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                \n",
    "                if url == search_url:\n",
    "                    search_results = soup.select('.grid-item > a')\n",
    "                    movie_url = None\n",
    "                    \n",
    "                    for result in search_results:\n",
    "                        result_text = result.get_text(strip=True)\n",
    "                        \n",
    "                        if similar(result_text, movie_title, 0.6) and str(year) in result_text:\n",
    "                            movie_url = urljoin(base_url, result['href'])\n",
    "                            print(f\"MovieStillsDB: Нашел совпадение для {movie_title} ({year}): {result_text}\")\n",
    "                            break\n",
    "                    \n",
    "                    if movie_url:\n",
    "                        response = requests.get(movie_url, headers=headers, timeout=15)\n",
    "                        if response.status_code == 200:\n",
    "                            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        continue\n",
    "                \n",
    "                image_links = soup.select('.grid-item > a')\n",
    "                \n",
    "                for link in image_links[:max_frames]:\n",
    "                    if 'href' in link.attrs:\n",
    "                        still_url = urljoin(base_url, link['href'])\n",
    "                        still_response = requests.get(still_url, headers=headers, timeout=15)\n",
    "                        \n",
    "                        if still_response.status_code == 200:\n",
    "                            still_soup = BeautifulSoup(still_response.text, 'html.parser')\n",
    "                            \n",
    "                            img_tag = still_soup.select_one('.largepic img')\n",
    "                            if img_tag and 'src' in img_tag.attrs:\n",
    "                                img_url = img_tag['src']\n",
    "                                if img_url.startswith('http'):\n",
    "                                    frame_urls.append(img_url)\n",
    "                                else:\n",
    "                                    frame_urls.append(urljoin(base_url, img_url))\n",
    "                \n",
    "                if frame_urls:\n",
    "                    print(f\"MovieStillsDB: Нашел {len(frame_urls)} кадров для {movie_title} ({year})\")\n",
    "                    break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении кадров из MovieStillsDB для {movie_title} ({year}): {e}\")\n",
    "    \n",
    "    return frame_urls\n",
    "\n",
    "def get_frames_from_film_grab(movie_title, year, max_frames=15):\n",
    "    frame_urls = []\n",
    "    \n",
    "    formatted_title = movie_title.lower().replace(' ', '-')\n",
    "    formatted_title = re.sub(r'[^\\w\\-]', '', formatted_title)\n",
    "    \n",
    "    search_url = f\"https://film-grab.com/?s={quote(movie_title)}\"\n",
    "    \n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(search_url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            search_results = soup.select('article.post')\n",
    "            \n",
    "            film_url = None\n",
    "            best_match_title = None\n",
    "            found_exact_match = False\n",
    "            \n",
    "            for result in search_results:\n",
    "                title_elem = result.select_one('h2.entry-title a')\n",
    "                if not title_elem:\n",
    "                    continue\n",
    "                \n",
    "                result_title = title_elem.text.strip()\n",
    "                \n",
    "                if similar(result_title, movie_title, 0.8) and str(year) in result_title:\n",
    "                    film_url = title_elem['href']\n",
    "                    best_match_title = result_title\n",
    "                    found_exact_match = True\n",
    "                    print(f\"Film-Grab: Нашел хорошее совпадение для {movie_title} ({year}): {result_title}\")\n",
    "                    break\n",
    "            \n",
    "            if not found_exact_match:\n",
    "                for result in search_results:\n",
    "                    title_elem = result.select_one('h2.entry-title a')\n",
    "                    if not title_elem:\n",
    "                        continue\n",
    "                    \n",
    "                    result_title = title_elem.text.strip()\n",
    "                    \n",
    "                    if similar(result_title, movie_title, 0.7):\n",
    "                        film_url = title_elem['href']\n",
    "                        best_match_title = result_title\n",
    "                        print(f\"Film-Grab: Нашел возможное совпадение для {movie_title} ({year}): {result_title}\")\n",
    "                        \n",
    "                        if str(year) in result_title:\n",
    "                            break\n",
    "            \n",
    "            if not film_url and search_results:\n",
    "                title_elem = search_results[0].select_one('h2.entry-title a')\n",
    "                if title_elem:\n",
    "                    result_title = title_elem.text.strip()\n",
    "                    if str(year) not in result_title and re.search(r'\\b(19|20)\\d{2}\\b', result_title):\n",
    "                        found_years = re.findall(r'\\b(19|20)\\d{2}\\b', result_title)\n",
    "                        if found_years and abs(int(found_years[0]) - int(year)) > 5:\n",
    "                            print(f\"Film-Grab: Пропуск результата для {movie_title} ({year}) из-за несоответствия года: {result_title}\")\n",
    "                            return frame_urls\n",
    "                    \n",
    "                    film_url = title_elem['href']\n",
    "                    best_match_title = result_title\n",
    "                    print(f\"Film-Grab: Использую первый результат для {movie_title} ({year}): {result_title}\")\n",
    "            \n",
    "            if film_url:\n",
    "                film_response = requests.get(film_url, headers=headers, timeout=10)\n",
    "                \n",
    "                if film_response.status_code == 200:\n",
    "                    film_soup = BeautifulSoup(film_response.text, 'html.parser')\n",
    "                    \n",
    "                    gallery_images = film_soup.select('div.entry-content img')\n",
    "                    \n",
    "                    for img in gallery_images[:max_frames]:\n",
    "                        if 'src' in img.attrs:\n",
    "                            img_url = img['src']\n",
    "                            if img_url.startswith('http'):\n",
    "                                frame_urls.append(img_url)\n",
    "                    \n",
    "                    if frame_urls:\n",
    "                        print(f\"Film-Grab: Получено {len(frame_urls)} кадров для {best_match_title}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при получении кадров из Film-Grab для {movie_title} ({year}): {e}\")\n",
    "    \n",
    "    return frame_urls\n",
    "\n",
    "def get_frames_from_imdb(imdb_id, max_frames=15):\n",
    "    frame_urls = []\n",
    "    \n",
    "    if not imdb_id:\n",
    "        return frame_urls\n",
    "    \n",
    "    url = f\"https://www.imdb.com/title/{imdb_id}/mediaindex\"\n",
    "    \n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            image_links = soup.select('div.media_index_thumb_list a img')\n",
    "            \n",
    "            for img in image_links[:max_frames]:\n",
    "                if 'src' in img.attrs:\n",
    "                    img_url = img['src']\n",
    "                    \n",
    "                    if '_V1_' in img_url:\n",
    "                        base_url = img_url.split('_V1_')[0]\n",
    "                        img_url = f\"{base_url}_V1_.jpg\"\n",
    "                    \n",
    "                    frame_urls.append(img_url)\n",
    "            \n",
    "            if frame_urls:\n",
    "                print(f\"IMDB: Получено {len(frame_urls)} кадров для фильма с ID {imdb_id}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при получении кадров из IMDB для фильма {imdb_id}: {e}\")\n",
    "    \n",
    "    return frame_urls\n",
    "\n",
    "def download_and_validate_frame(url, output_path, min_width=500, min_brightness=30, min_file_size=20000):\n",
    "    try:\n",
    "        headers = {\"User-Agent\": USER_AGENT}\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return False\n",
    "        \n",
    "        if len(response.content) < min_file_size:\n",
    "            return False\n",
    "        \n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        width, height = image.size\n",
    "        if width < min_width:\n",
    "            return False\n",
    "        \n",
    "        img_gray = image.convert('L')\n",
    "        brightness = np.mean(np.array(img_gray))\n",
    "        if brightness < min_brightness:\n",
    "            return False\n",
    "        \n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке {url}: {e}\")\n",
    "        return False\n",
    "\n",
    "def get_next_frame_number(movie_dir):\n",
    "    existing_frames = [f for f in os.listdir(movie_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if not existing_frames:\n",
    "        return 0\n",
    "    \n",
    "    frame_numbers = []\n",
    "    for frame in existing_frames:\n",
    "        match = re.search(r'frame_(\\d+)', frame)\n",
    "        if match:\n",
    "            frame_numbers.append(int(match.group(1)))\n",
    "    \n",
    "    if not frame_numbers:\n",
    "        return 0\n",
    "    \n",
    "    return max(frame_numbers) + 1\n",
    "\n",
    "def process_movie_additional_frames(movie_id, movie_data, output_dir, sources_limit=3):\n",
    "    movie_dir = os.path.join(output_dir, str(movie_id))\n",
    "    os.makedirs(movie_dir, exist_ok=True)\n",
    "    \n",
    "    stats = {\n",
    "        \"downloaded\": 0,\n",
    "        \"filtered\": 0,\n",
    "        \"errors\": 0,\n",
    "        \"sources_used\": []\n",
    "    }\n",
    "    \n",
    "    original_title = movie_data.get(\"original_title\", \"\")\n",
    "    year = movie_data.get(\"year\", \"\")\n",
    "    imdb_id = movie_data.get(\"imdb_id\", \"\")\n",
    "    \n",
    "    if not imdb_id and TMDB_API_KEY:\n",
    "        imdb_id = get_imdb_id(movie_id, TMDB_API_KEY)\n",
    "    \n",
    "    existing_frames_count = len([f for f in os.listdir(movie_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    \n",
    "    if existing_frames_count >= MAX_FRAMES_PER_MOVIE:\n",
    "        return stats\n",
    "    \n",
    "    frames_needed = MAX_FRAMES_PER_MOVIE - existing_frames_count\n",
    "    \n",
    "    next_frame_num = get_next_frame_number(movie_dir)\n",
    "\n",
    "    sources = [\n",
    "        (get_frames_from_movie_stills_db, (original_title, year, imdb_id, frames_needed), \"MovieStillsDB\"),\n",
    "        (get_frames_from_film_grab, (original_title, year, frames_needed), \"FilmGrab\"),\n",
    "        (get_frames_from_imdb, (imdb_id, frames_needed), \"IMDB\")\n",
    "    ]\n",
    "    \n",
    "    random.shuffle(sources)\n",
    "    \n",
    "    sources = sources[:sources_limit]\n",
    "    \n",
    "    for func, params, source_name in sources:\n",
    "        frames_count = len([f for f in os.listdir(movie_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        if frames_count >= MAX_FRAMES_PER_MOVIE:\n",
    "            break\n",
    "        \n",
    "        if source_name == \"IMDB\" and not imdb_id:\n",
    "            continue\n",
    "        \n",
    "        frame_urls = func(*params)\n",
    "        \n",
    "        if frame_urls:\n",
    "            stats[\"sources_used\"].append(source_name)\n",
    "        \n",
    "        frames_needed = MAX_FRAMES_PER_MOVIE - frames_count\n",
    "        \n",
    "        for i, url in enumerate(frame_urls):\n",
    "            if stats[\"downloaded\"] >= frames_needed:\n",
    "                break\n",
    "            \n",
    "            output_path = os.path.join(movie_dir, f\"frame_{next_frame_num + i:03d}.jpg\")\n",
    "            \n",
    "            time.sleep(random.uniform(0.2, 0.5))\n",
    "            \n",
    "            if download_and_validate_frame(\n",
    "                url, \n",
    "                output_path, \n",
    "                min_width=MIN_WIDTH,\n",
    "                min_brightness=MIN_BRIGHTNESS,\n",
    "                min_file_size=MIN_FILE_SIZE\n",
    "            ):\n",
    "                stats[\"downloaded\"] += 1\n",
    "            else:\n",
    "                stats[\"filtered\"] += 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def process_all_movies_additional_frames(metadata_file, output_dir, max_threads=5, limit_movies=None):\n",
    "    movies_metadata = load_movie_metadata(metadata_file)\n",
    "    \n",
    "    if limit_movies and limit_movies < len(movies_metadata):\n",
    "        movie_ids = list(movies_metadata.keys())\n",
    "        random.shuffle(movie_ids)\n",
    "        movie_ids = movie_ids[:limit_movies]\n",
    "        limited_metadata = {movie_id: movies_metadata[movie_id] for movie_id in movie_ids}\n",
    "        movies_metadata = limited_metadata\n",
    "        print(f\"Обработка ограничена {limit_movies} фильмами\")\n",
    "    \n",
    "    total_stats = {\"downloaded\": 0, \"filtered\": 0, \"errors\": 0, \"sources_used\": set()}\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "        future_to_movie = {\n",
    "            executor.submit(\n",
    "                process_movie_additional_frames, \n",
    "                movie_id, \n",
    "                movie_data, \n",
    "                output_dir\n",
    "            ): (movie_id, movie_data) \n",
    "            for movie_id, movie_data in movies_metadata.items()\n",
    "        }\n",
    "        \n",
    "        for future in tqdm(concurrent.futures.as_completed(future_to_movie), total=len(movies_metadata), desc=\"Дополнительные кадры\"):\n",
    "            movie_id, movie_data = future_to_movie[future]\n",
    "            \n",
    "            try:\n",
    "                stats = future.result()\n",
    "                \n",
    "                total_stats[\"downloaded\"] += stats[\"downloaded\"]\n",
    "                total_stats[\"filtered\"] += stats[\"filtered\"]\n",
    "                total_stats[\"errors\"] += stats[\"errors\"]\n",
    "                total_stats[\"sources_used\"].update(stats[\"sources_used\"])\n",
    "                \n",
    "                movie_dir = os.path.join(output_dir, str(movie_id))\n",
    "                if os.path.exists(movie_dir):\n",
    "                    frame_count = len([f for f in os.listdir(movie_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "                    movies_metadata[movie_id][\"frame_count\"] = frame_count\n",
    "                    \n",
    "                    if stats[\"downloaded\"] > 0:\n",
    "                        print(f\"Добавлено {stats['downloaded']} кадров для фильма {movie_data.get('title')} ({movie_id}) из источников: {', '.join(stats['sources_used'])}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при обработке фильма {movie_id}: {e}\")\n",
    "                total_stats[\"errors\"] += 1\n",
    "    \n",
    "    updated_metadata_file = os.path.join(os.path.dirname(metadata_file), \"movies_with_additional_frames.json\")\n",
    "    with open(updated_metadata_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(movies_metadata, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    total_stats[\"sources_used\"] = list(total_stats[\"sources_used\"])\n",
    "    \n",
    "    return total_stats, movies_metadata\n",
    "\n",
    "\n",
    "limit_movies = 10\n",
    "\n",
    "print(f\"Запуск сбора дополнительных кадров из альтернативных источников...\")\n",
    "print(f\"Максимальное количество кадров для каждого фильма: {MAX_FRAMES_PER_MOVIE}\")\n",
    "print(f\"Количество параллельных потоков: {MAX_THREADS}\")\n",
    "\n",
    "total_stats, updated_metadata = process_all_movies_additional_frames(\n",
    "    INPUT_FILE, \n",
    "    OUTPUT_DIR, \n",
    "    MAX_THREADS,\n",
    "    limit_movies\n",
    ")\n",
    "\n",
    "print(\"\\nСтатистика дополнительных кадров:\")\n",
    "print(f\"Всего скачано новых кадров: {total_stats['downloaded']}\")\n",
    "print(f\"Отфильтровано низкокачественных кадров: {total_stats['filtered']}\")\n",
    "print(f\"Ошибок при скачивании: {total_stats['errors']}\")\n",
    "print(f\"Использованы источники: {', '.join(total_stats['sources_used'])}\")\n",
    "\n",
    "print(\"\\nФильмы с наибольшим количеством кадров:\")\n",
    "top_movies = sorted([(movie_id, data[\"frame_count\"]) for movie_id, data in updated_metadata.items() if \"frame_count\" in data], \n",
    "                     key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "for movie_id, count in top_movies:\n",
    "    if movie_id in updated_metadata:\n",
    "        print(f\"{updated_metadata[movie_id]['title']}: {count} кадров\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d980b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
